# SUGGEST FOR IMPROVEMENT
## ðŸ“‹ **NEW PIPELINE WORKFLOW**

| Step | Description | Status | Changes & Rationale |
|------|-------------|--------|---------------------|
| 1 | **Train/Test Split** | ðŸ”„ In Progress | **MOVED TO EARLY** - Split image IDs before augmentation to prevent data leakage |
| 2 | **Load Captions** | âœ… No Change | Read captions.txt â†’ image_to_captions_mapping (40,455 captions / 8,091 images) |
| 3 | **Preprocessing Captions** | âœ… No Change | Clean text + add startseq/endseq tokens |
| 4 | **Tokenization & Vocabulary** | ðŸ”„ To Update | **FIT ONLY ON TRAINING** captions to avoid data leakage |
| 5 | **Data Augmentation (Train Only)** | ðŸ”„ To Update | **TRAIN SET ONLY** - Use ImageDataGenerator for augmentation_factor=1-3 |
| 6 | **Feature Extraction** | ðŸ”„ To Update | **MOVED AFTER AUGMENTATION** - Extract features for train(original+aug) + test(original) |
| 7 | **Data Generator** | âœ… No Change | Generate batches (image_feature, in_seq) â†’ out_seq |
| 8 | **Model Training (GRU)** | ðŸ”„ To Update | Switched from BiLSTM to GRU to reduce parameters and speed up training with comparable performance |
| 9 | **Evaluation (BLEU)** | âœ… No Change | BLEU-1, BLEU-2 on test set |



## ðŸ§  **ARCHITECTURE UPDATE DETAILS (BiLSTM â†’ GRU)**

- Rationale:
  - Fewer parameters than BiLSTM for the same hidden size.
  - Faster training and lower memory usage.
  - Maintains comparable captioning quality in practice.

- Key changes in decoder:
  - Replace Bidirectional LSTM layers with single-direction GRU.
  - Keep attention mechanism unchanged.


## ðŸ“Š **DATA FLOW COMPARISON**

### ðŸ”´ **ORIGINAL FLOW (Has Data Leakage)**
```
1. Load Images â†’ Extract Features (ALL)
2. Load Captions â†’ Process ALL captions  
3. Augment ALL images â†’ Mixed train/test
4. Tokenize ALL captions â†’ Data leakage
5. Split â†’ Too late, leakage already occurred
6. Train â†’ Contaminated data
```

### âœ… **NEW FLOW (No Data Leakage)**
```
1. Load Captions â†’ Split Image IDs (train_ids/test_ids)
2. Tokenize ONLY training captions â†’ No leakage  
3. Augment ONLY train_ids â†’ Clean separation
4. Extract Features: train(orig+aug) + test(orig only)
5. Train (GRU) â†’ Clean training data
6. Evaluate â†’ Unbiased test results
```



